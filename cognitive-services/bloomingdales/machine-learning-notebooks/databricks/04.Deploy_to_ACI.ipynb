{"cells":[{"cell_type":"markdown","source":["Azure ML & Azure Databricks notebooks by Parashar Shah.\n\nCopyright (c) Microsoft Corporation. All rights reserved.\n\nLicensed under the MIT License."],"metadata":{}},{"cell_type":"markdown","source":["Please ensure you have run all previous notebooks in sequence before running this."],"metadata":{}},{"cell_type":"markdown","source":["Please Register Azure Container Instance(ACI) using Azure Portal: https://docs.microsoft.com/en-us/azure/azure-resource-manager/resource-manager-supported-services#portal in your subscription before using the SDK to deploy your ML model to ACI."],"metadata":{}},{"cell_type":"code","source":["from azureml.core import Workspace\nimport azureml.core\n\n# Check core SDK version number\nprint(\"SDK version:\", azureml.core.VERSION)\n\n#'''\nws = Workspace.from_config()\nprint('Workspace name: ' + ws.name, \n      'Azure region: ' + ws.location, \n      'Subscription id: ' + ws.subscription_id, \n      'Resource group: ' + ws.resource_group, sep = '\\n')\n#'''"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["##NOTE: service deployment always gets the model from the current working dir.\nimport os\n\nmodel_name = \"AdultCensus.mml\" # OR AdultCensus_runHistory.mml\nmodel_name_dbfs = os.path.join(\"/dbfs\", model_name)\n\nprint(\"copy model from dbfs to local\")\nmodel_local = \"file:\" + os.getcwd() + \"/\" + model_name\ndbutils.fs.cp(model_name, model_local, True)"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":["#Register the model\nfrom azureml.core.model import Model\nmymodel = Model.register(model_path = model_name, # this points to a local file\n                       model_name = model_name, # this is the name the model is registered as, am using same name for both path and name.                 \n                       description = \"ADB trained model by Parashar\",\n                       workspace = ws)\n\nprint(mymodel.name, mymodel.description, mymodel.version)"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"code","source":["#%%writefile score_sparkml.py\nscore_sparkml = \"\"\"\n\nimport json\n\ndef init():\n    try:\n        # One-time initialization of PySpark and predictive model\n        import pyspark\n        from azureml.core.model import Model\n        from pyspark.ml import PipelineModel\n        \n        global trainedModel\n        global spark\n        \n        spark = pyspark.sql.SparkSession.builder.appName(\"ADB and AML notebook by Parashar\").getOrCreate()\n        model_name = \"{model_name}\" #interpolated\n        model_path = Model.get_model_path(model_name)\n        trainedModel = PipelineModel.load(model_path)\n    except Exception as e:\n        trainedModel = e\n    \ndef run(input_json):\n    if isinstance(trainedModel, Exception):\n        return json.dumps({{\"trainedModel\":str(trainedModel)}})\n      \n    try:\n        sc = spark.sparkContext\n        input_list = json.loads(input_json)\n        input_rdd = sc.parallelize(input_list)\n        input_df = spark.read.json(input_rdd)\n    \n        # Compute prediction\n        prediction = trainedModel.transform(input_df)\n        #result = prediction.first().prediction\n        predictions = prediction.collect()\n\n        #Get each scored result\n        preds = [str(x['prediction']) for x in predictions]\n        result = \",\".join(preds)\n    except Exception as e:\n        result = str(e)\n    return json.dumps({{\"result\":result}})\n    \n\"\"\".format(model_name=model_name)\n\nexec(score_sparkml)\n\nwith open(\"score_sparkml.py\", \"w\") as file:\n    file.write(score_sparkml)"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["from azureml.core.conda_dependencies import CondaDependencies \n\nmyacienv = CondaDependencies.create(conda_packages=['scikit-learn','numpy','pandas'])\n\nwith open(\"mydeployenv.yml\",\"w\") as f:\n    f.write(myacienv.serialize_to_string())"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"code","source":["#deploy to ACI\nfrom azureml.core.webservice import AciWebservice, Webservice\n\nmyaci_config = AciWebservice.deploy_configuration(\n    cpu_cores = 1, \n    memory_gb = 1, \n    tags = {'name':'Databricks Azure ML ACI'}, \n    description = 'This is for ADB and AML example. Azure Databricks & Azure ML SDK demo with ACI by Parashar.')"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"code","source":["# this will take 10-15 minutes to finish\n\nservice_name = \"aciws\"\nruntime = \"spark-py\" \ndriver_file = \"score_sparkml.py\"\nmy_conda_file = \"mydeployenv.yml\"\n\n# image creation\nfrom azureml.core.image import ContainerImage\nmyimage_config = ContainerImage.image_configuration(execution_script = driver_file, \n                                    runtime = runtime, \n                                    conda_file = my_conda_file)\n\n# Webservice creation\nmyservice = Webservice.deploy_from_model(\n  workspace=ws, \n  name=service_name,\n  deployment_config = myaci_config,\n  models = [mymodel],\n  image_config = myimage_config\n    )\n\nmyservice.wait_for_deployment(show_output=True)"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"code","source":["help(ContainerImage)"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"code","source":["# List images by ws\n\nfor i in ContainerImage.list(workspace = ws):\n    print('{}(v.{} [{}]) stored at {} with build log {}'.format(i.name, i.version, i.creation_state, i.image_location, i.image_build_log_uri))"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"code","source":["#for using the Web HTTP API \nprint(myservice.scoring_uri)"],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"code","source":["import json\n\n#get the some sample data\ntest_data_path = \"AdultCensusIncomeTest\"\ntest = spark.read.parquet(test_data_path).limit(5)\n\ntest_json = json.dumps(test.toJSON().collect())\n\nprint(test_json)"],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"code","source":["#using data defined above predict if income is >50K (1) or <=50K (0)\nmyservice.run(input_data=test_json)"],"metadata":{},"outputs":[],"execution_count":15},{"cell_type":"code","source":["#comment to not delete the web service\nmyservice.delete()"],"metadata":{},"outputs":[],"execution_count":16},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":17}],"metadata":{"name":"04.DeploytoACI","notebookId":3874566296719333},"nbformat":4,"nbformat_minor":0}
